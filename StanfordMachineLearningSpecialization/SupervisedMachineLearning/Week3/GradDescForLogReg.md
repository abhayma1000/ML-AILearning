## Gradient Descent Implementation
* Again want to minimize $J(w,b)$
* Repeat the same gradient descent algorithm:
  * However with a new derivative term because new cost function
  * ![Img](../../../Images/Pasted%20Graphic%2011.png)
  * Img
  * Looks like the same derivative term as lin. reg., but the function $f_{\vec{w},b}$ for log. reg. is different
  * ![Img](../../../Images/Pasted%20Graphic%2012.png)